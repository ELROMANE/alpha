# beep-buddy

## Overview

beep-buddy bridges AI intelligence and physical robotics, creating a personal assistant that understands emotions and responds with meaningful physical actions. This project tightly integrates software intelligence and hardware expressiveness, making technology feel more human.

## Features

- **Physical Actions & Voice Interaction:**  
  Servo motor movements and expressive gestures respond to user input, while integrated speech-to-text and text-to-speech capabilities enable natural voice conversations.

- **Multi-Modal & Robust Operation:**  
  Supports voice, text, and emotion detection with continuous operation and fallback mechanisms, ensuring reliable performance even if some components fail.

## Getting Started

1. **Clone the repo:**
   ```bash
   git clone https://github.com/ELROMANE/beep-buddy.git
   ```

2. **Set up hardware:**
   - Connect servo motors to Arduino or compatible board.
   - (Optional) Add microphone, speaker, or camera as needed.

3. **Install dependencies:**
   - See `requirements.txt` and `hardware_setup.md` for instructions.

4. **Run the application:**
   ```bash
   python main.py
   ```

## Contributing

We welcome contributions! See [`CONTRIBUTING.md`](CONTRIBUTING.md) for guidelines.  
- **Issues:** [GitHub Issues](https://github.com/ELROMANE/beep-buddy/issues)  
- **Discussions:** [GitHub Discussions](https://github.com/ELROMANE/beep-buddy/discussions)

## Contact

For questions or support, open an issue or join the discussion on [GitHub Discussions](https://github.com/ELROMANE/beep-buddy/discussions).
